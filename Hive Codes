# Entering hive
hive

# Checking the databases stored in Hive
show databases;

# Creating a database
create database if not exists A;

# Using a database
Use A;

# Checking location from hdfs
hadoop fs -ls /user/hive/warehouse

# Creating a managed table
create table if not exists emp(empno int, ename string, sal float, comm float, dpno int) row format delimited fields terminated by ',’;
describe emp;

# Loading a table into the schema created
load data local inpath '/home/cloudera/Desktop/emp.csv' into table emp;

# Displaying all records
Select * from emp;

# Creating an external table
create external table  ext_emp1(empno int, ename string, sal float, comm float, dpno int) row format delimited fields terminated by ',’ location '/user/cloudera/data/emp’;
#While giving path we have to give only directory path not file name
#Here, table will be in given hdfs path.

# Creating an external table without location
create external table  ext_emp2(empno int, ename string, sal float, comm float, dpno int) row format delimited fields terminated by ‘,’;
#Table will be stored under /user/hive/warehouse/A.db/ext_emp2/emp

# Loading data ffrom local onto an external table that was created
load data local inpath '/home/cloudera/Desktop/empdata' into table ext_emp2;

# Partitioning files
set hive.exec.dynamic.partition.mode;
set hive.exec.dynamic.partition.mode=nonstrict;

create external table emp_dept (empno int, ename string, sal float, comm float) partitioned by (dpno int) row format delimited fields terminated by ',’;
insert into table emp_dept partition(dpno) select * from emp;

# Checking to see if the partitions exist
hadoop fs -ls /user/hive/warehouse/A.db
